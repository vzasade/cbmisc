https://docs.google.com/document/d/19M10Em2zV_5QgAxax2tW9i8mwyEyKYyL2qZBSFn9a_0



1. Cleans up only membase buckets
2. Check if all bucket servers are active kv nodes. Error out if it is not so. If bucket has no servers => populate it's servers with all active kv nodes and start cleanup from the beginning.
3. If the bucket's map is empty => set initial map and start cleanup from the beginning.

4. janitor_agent:query_vbuckets - query vbucket states from memcached on all bucket servers. Stops replication for failover_nodes.

5. maybe_fixup_vbucket_map - here we sometime update vbucket map

6. find_unsafe_nodes_with_vbucket_states - uses fetched states and vbucket map to find nodes with possible data loss - issues {error, unsafe_nodes, UnsafeNodes}



    %% Find all the unsafe nodes (nodes on which memcached restarted within
    %% the auto-failover timeout) using the vbucket states. If atleast one
    %% unsafe node is found then we won't bring the bucket online until we
    %% we reprovision it. Reprovisioning is initiated by the orchestrator at
    %% the end of every janitor run.


%% Condition that indicates possibility of data loss:
%% A vBucket is "missing" on a node where it is supposed to be active as per the
%% vBucket map, it is not active elsewhere in the cluster, and the vBucket is in
%% replica state on some other node[s]. If such a vBucket is brought online on
%% the node supposed to be its current master, then it will come up empty and
%% when the replication streams are establised the replicas will also lose their
%% data.



should_check_for_unsafe_nodes(BCfg, Options) ->
    proplists:get_bool(check_for_unsafe_nodes, Options) andalso
        ns_bucket:storage_mode(BCfg) =:= ephemeral.


https://review.couchbase.org/c/ns_server/+/76396

MB-22208: Add auto-reprovision handling module.

PROBLEM STATEMENT: With ephemeral buckets around, if the
memcached process restarts on any node within the auto
failover timeout, then we will bring the bucket online on
that node which can lead to data-loss as the ACTIVE copy will
have no data upon restart and the REPLICA will also lose
data when the DCP connections are re-established.

SOLUTION: To handle this case, the janitor during cleanup
will look for the condition where a vbucket's MASTER is
marked as missing. These nodes are dubbed as 'unsafe' nodes.
If the janitor finds any such instance then the bucket will
not be brought online immediately and it'll will pass a list
of all unsafe nodes found back to the orchestrator. The
orchestrator will use this information to reprovision the
bucket by promoting a REPLICA of the respective vbuckets and
then bring the bucket online.

This change introduces the following:
[1] A new module which would be responsible for automatically
    reprovisioning the buckets given a list of unsafe nodes.
    This change only introduces the configuration related APIs.

[2] We store the configuration info in ns_config and a default
    config has been added to ns_config_default module. The auto
    reprovision config contains the following params:
    [a] enabled - indicates whether the feature is enabled or not.
    [b] max_nodes - indicates max # of auto-reprovision operations
                    that can be performed.
    [c] count - the current number of auto-reprovisions performed.


https://review.couchbase.org/c/ns_server/+/76398

MB-22208: Reprovision buckets upon memcached restart.

The following are the changes:

[1] The orchestrator has been changed to pick up all the
janitor items first and then call ns_janitor:cleanup on them
one at a time. Earlier we should to spawn a sub-process for
every janitor item but now we just use on sub-process to
cleanup all the janitor items.

[2] The orchestrator gets a list of unsafe nodes, if any,
from the janitor which it then passes to the auto reprovision
module to promote the respective REPLICAs for affected
vbuckets.

[3] The janitor cleanup now looks for unsafe nodes. These
are the nodes on which the memcached process has restarted
within auto-failover timeout and by virtue of which the
ACTIVEs are found to be in missing state for certain vbuckets.
If unsafe nodes are found then the janitor doesn't bring
the bucket online at all but simply return the list of
unsafe nodes back to the orchestrator.

[4] The auto-reprovision module now hosts a new API called
"reprovision_buckets" which takes in a list of ephemeral
buckets and unsafe nodes. It then promotes the REPLICAs
and persists this information in the bucket config. The
bucket will be brought online during the next janitor run.
This API also updates the auto-reprovision count and if the
count exceeds the max_nodes configured then disables the
feature until the count is reset. The actual ns_config will
be updated with latest bucket configs and auto-reprovision
count as a single transaction.

MB-22208: Clear reprovision count after rebalance.

We allow auto-reprovisioning to be done on 'max_nodes' #
of nodes & we track the actual number of nodes that have
been auto-reprovisioned in ns_config. If we have reached
the 'max_nodes' limit then we don't perform any more
auto-reprovisioning. This count needs to be cleared after
the buckets are rebalanced.

MB-22208: Orchestrator to delegate janitor...

...cleanup to the new gen_server module.

The following are the changes:
[1] All the logic pertaining to janitor cleanup is moved into the
    new module.
[2] ns_orchestrator module still maintains the periodic timer to
    to initiate janitor run. It does so by calling the 'start_cleanup'
    API provided by the ns_janitor_server module. The returned ID will
    be stored in the janitor_running state's data and orchestrator
    transitions into 'janitor_running' state.
[3] While in 'janitor_running' state, if the orchestrator receives
    a new event, then the cleanup is terminated by calling the
    'terminate_cleanup' API.
[4] When the cleanup completes succesfully, the ns_janitor_server
    module sends an async 'cleanup_done' event which indicates whether
    any unsafe nodes were found. If found, then the orchestrator will
    trigger an auto_reprovision operation to mend the affected buckets'
    configurations. The orchestrator moves into 'idle' state before
    triggering the auto_reprovision.
[5] When the cleanup is terminated, as part of sub-process shutdown,
    all the requestors of janitor run will be notified with an
    'interrupted' return value. So we can drop the explicit attempts
    we make to notify the requestors after orchestrator state
    transitions.


https://review.couchbase.org/c/ns_server/+/76771

MB-22208: REST APIs to manage auto-reprovision...

...configuration.

The APIs following are added:
[1] To dump the current configuration.
[2] To assign new values to the configuration parameters.
[3] To reset the auto-reprovision count. The actual operation is
    routed via the orchestrator.

https://issues.couchbase.com/browse/MB-22208

Per the PRD, Ephemeral Buckets require a modification to the failover policy. The basic premise with Ephemeral buckets is as follows:

If the memcached process on a node is restarted, favour autofailover and the promotion of replicas over the inevitable data loss, regardless of autofailover timeout.

The minimum requirement is to achieve this in the simple case, where a node only carries Ephemeral buckets and other autofailover criteria are met (replicas configured, failover count allows it etc.). 


Auto-reprovisioning is needed for Ephemeral buckets to guard against data loss when a Data node fails but restarts before an auto-failover could occur. It enables automatic promotion of replicas to active for that node. Here you can configure the number of nodes for which auto-provisioning should be done. Ideally, this number should be set to 1; higher values should only be used if the surviving nodes have enough capacity to handle increased workload. A cluster rebalance must be done once the restarted node becomes healthy.



ps -e | grep memcached.json

